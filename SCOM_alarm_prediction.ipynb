{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\SRAVANTHI\n",
      "[nltk_data]     SHOROFF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\SRAVANTHI\n",
      "[nltk_data]     SHOROFF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\SRAVANTHI\n",
      "[nltk_data]     SHOROFF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re, pickle\n",
    "le = LabelEncoder()\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alert</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Server</th>\n",
       "      <th>Action</th>\n",
       "      <th>Alert Type(ignorable)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CL - Service Account Lockout</td>\n",
       "      <td>Very Low</td>\n",
       "      <td>any server</td>\n",
       "      <td>1. Look for the account locked out name from A...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>KCC cannot compute a replication path</td>\n",
       "      <td>Very Low</td>\n",
       "      <td>any server</td>\n",
       "      <td>Ignore the alert, if it is excessively repeati...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AD,Mail,Lync alerts</td>\n",
       "      <td>Medium</td>\n",
       "      <td>any server</td>\n",
       "      <td>p2 case to WP server application team and drop...</td>\n",
       "      <td>doubt(needs discussion)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Backup device failed - Operating system error</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drop a mail to Wintel team and backup team</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>IIS 7 Web site is unavailable</td>\n",
       "      <td>Critical</td>\n",
       "      <td>any server</td>\n",
       "      <td>Drop a mail to Wintel team</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Alert  Severity      Server  \\\n",
       "0                   CL - Service Account Lockout  Very Low  any server   \n",
       "1          KCC cannot compute a replication path  Very Low  any server   \n",
       "2                            AD,Mail,Lync alerts    Medium  any server   \n",
       "3  Backup device failed - Operating system error       Low         NaN   \n",
       "4                  IIS 7 Web site is unavailable  Critical  any server   \n",
       "\n",
       "                                              Action    Alert Type(ignorable)  \n",
       "0  1. Look for the account locked out name from A...                      Yes  \n",
       "1  Ignore the alert, if it is excessively repeati...                      yes  \n",
       "2  p2 case to WP server application team and drop...  doubt(needs discussion)  \n",
       "3         Drop a mail to Wintel team and backup team                       No  \n",
       "4                         Drop a mail to Wintel team                       NO  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r\"SCOM.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Alert', 'Severity', 'Server', 'Action', 'Alert Type(ignorable)'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           CL - Service Account Lockout\n",
       "1                  KCC cannot compute a replication path\n",
       "2                                    AD,Mail,Lync alerts\n",
       "3          Backup device failed - Operating system error\n",
       "4                          IIS 7 Web site is unavailable\n",
       "                             ...                        \n",
       "327                         \\nCertificate lifespan alert\n",
       "328    Failed to ping or bind to the Domain Naming Ma...\n",
       "329         Folder Redirection CSE Processed With Errors\n",
       "330      Application pool worker process is unresponsive\n",
       "331    Exchange Control Panel connectivity (External)...\n",
       "Name: Alert, Length: 332, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Alert'].dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          Yes\n",
       "1                          yes\n",
       "2      doubt(needs discussion)\n",
       "3                           No\n",
       "4                           NO\n",
       "                ...           \n",
       "327                         no\n",
       "328                        yes\n",
       "329                        yes\n",
       "330                         no\n",
       "331                         no\n",
       "Name: Alert Type(ignorable), Length: 330, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Alert Type(ignorable)'].dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "df['Alert Type(ignorable)'] = df['Alert Type(ignorable)'].replace(to_replace=['NO','no','No(needs discussion)'],value='No')\n",
    "df['Alert Type(ignorable)'] = df['Alert Type(ignorable)'].replace(to_replace=['yes','yes(server decom)','yes( server decom)'],value='Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    173\n",
       "No     151\n",
       "Name: Alert Type(ignorable), dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Alert Type(ignorable)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df['Alert Type(ignorable)'] == 'doubt(needs discussion)'].index,inplace=True)\n",
    "df.dropna(subset=['Alert Type(ignorable)'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Alert'] = df['Alert'].apply(lambda x: x.lower())\n",
    "df['Alert'] = df['Alert'].apply(lambda s: re.sub(r\"[^a-zA-Z0-9]\",\" \",s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmetization\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens =[w for w in tokens if not w in stop] # [w for w in\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in tokens])\n",
    "    return lemmatized_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             cl service account lockout\n",
       "1                           kcc compute replication path\n",
       "3            backup device failed operating system error\n",
       "4                              ii 7 web site unavailable\n",
       "5      sql server database configuration monitoring d...\n",
       "                             ...                        \n",
       "327                           certificate lifespan alert\n",
       "328    failed ping bind domain naming master fsmo rol...\n",
       "329               folder redirection cse processed error\n",
       "330         application pool worker process unresponsive\n",
       "331    exchange control panel connectivity external t...\n",
       "Name: Alert, Length: 324, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Alert'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "alerts = le.fit_transform(df['Alert'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'labelencoder.pkl'\n",
    "pickle.dump(alerts, open('labelencoder.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = pickle.load(open(\"labelencoder.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 51,   0,  39, 133, 244,  74,   9,  93, 135, 158,  63, 113,  80,\n",
       "        87, 154, 180, 178, 121, 303, 252, 223,  83, 125, 231, 211, 200,\n",
       "        30, 261,   6,   1, 169, 182, 167, 149, 154, 155, 127, 260, 313,\n",
       "         8,  70,  32, 151,  64,  62, 229, 302, 143,  53,  96, 122, 123,\n",
       "       124, 126, 129, 130, 131,  52, 120,  98, 118, 119,  61, 128, 117,\n",
       "        75, 176,  84, 278, 264,   8, 181,  17,  19,  23,  24,  36,  38,\n",
       "        20,  21,  50,  68, 103, 106,  95, 116, 165, 161, 217, 222, 240,\n",
       "       272, 286, 311, 316, 315, 187, 188, 189, 215, 258, 273, 281, 290,\n",
       "       291, 297, 314, 230,   7,  31, 268,  26, 267, 153, 289, 292, 288,\n",
       "       285, 280, 274, 262, 248, 233, 226, 221, 220, 202, 185, 166, 162,\n",
       "       157, 156, 145, 142, 140, 132,  91,  55,  46,  18,  29,  28,  14,\n",
       "        11, 296, 206, 295, 173, 201, 254, 172, 171, 100,  99,  97,  79,\n",
       "       186,  58, 190, 191, 192, 193, 194, 195, 196, 197, 232, 107, 177,\n",
       "        81, 298, 246, 178, 137,  12,  13,  16,  22,  34,  47,  54,  60,\n",
       "       109, 138, 203, 204, 207, 227, 228, 241, 250, 276,  25, 208,  88,\n",
       "       139, 212, 144, 111, 308, 256,  39,  41,  42,   2, 237, 238, 239,\n",
       "        15,  66,  67,  71,  72, 242, 243,  73,  74,  76,  77, 101, 102,\n",
       "       108, 146,  89,  86, 257,  33, 170, 214,  56,  57,  65, 184,  69,\n",
       "       147, 198, 199, 210, 213, 219, 249, 275, 299, 300, 301, 304, 305,\n",
       "        85, 218, 279, 306, 174, 175, 179, 287,  92, 205, 112, 310, 263,\n",
       "        82, 114, 115, 294,  48, 160, 163, 269, 270, 271, 164, 312, 251,\n",
       "       282, 265, 293,  49, 277, 283,  27, 168, 245, 134, 225, 224, 234,\n",
       "       235, 236, 253, 284, 309, 136,  45,  44,  44,  43, 159, 110, 216,\n",
       "       307, 183, 152,   4, 255,  59,  35, 247,   5,  90, 209,  10, 141,\n",
       "       104,  40, 150, 148, 259, 266,  78,   3, 105, 109,  37,  94],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 51]\n",
      " [  0]\n",
      " [ 39]\n",
      " [133]\n",
      " [244]\n",
      " [ 74]\n",
      " [  9]\n",
      " [ 93]\n",
      " [135]\n",
      " [158]\n",
      " [ 63]\n",
      " [113]\n",
      " [ 80]\n",
      " [ 87]\n",
      " [154]\n",
      " [180]\n",
      " [178]\n",
      " [121]\n",
      " [303]\n",
      " [252]\n",
      " [223]\n",
      " [ 83]\n",
      " [125]\n",
      " [231]\n",
      " [211]\n",
      " [200]\n",
      " [ 30]\n",
      " [261]\n",
      " [  6]\n",
      " [  1]\n",
      " [169]\n",
      " [182]\n",
      " [167]\n",
      " [149]\n",
      " [154]\n",
      " [155]\n",
      " [127]\n",
      " [260]\n",
      " [313]\n",
      " [  8]\n",
      " [ 70]\n",
      " [ 32]\n",
      " [151]\n",
      " [ 64]\n",
      " [ 62]\n",
      " [229]\n",
      " [302]\n",
      " [143]\n",
      " [ 53]\n",
      " [ 96]\n",
      " [122]\n",
      " [123]\n",
      " [124]\n",
      " [126]\n",
      " [129]\n",
      " [130]\n",
      " [131]\n",
      " [ 52]\n",
      " [120]\n",
      " [ 98]\n",
      " [118]\n",
      " [119]\n",
      " [ 61]\n",
      " [128]\n",
      " [117]\n",
      " [ 75]\n",
      " [176]\n",
      " [ 84]\n",
      " [278]\n",
      " [264]\n",
      " [  8]\n",
      " [181]\n",
      " [ 17]\n",
      " [ 19]\n",
      " [ 23]\n",
      " [ 24]\n",
      " [ 36]\n",
      " [ 38]\n",
      " [ 20]\n",
      " [ 21]\n",
      " [ 50]\n",
      " [ 68]\n",
      " [103]\n",
      " [106]\n",
      " [ 95]\n",
      " [116]\n",
      " [165]\n",
      " [161]\n",
      " [217]\n",
      " [222]\n",
      " [240]\n",
      " [272]\n",
      " [286]\n",
      " [311]\n",
      " [316]\n",
      " [315]\n",
      " [187]\n",
      " [188]\n",
      " [189]\n",
      " [215]\n",
      " [258]\n",
      " [273]\n",
      " [281]\n",
      " [290]\n",
      " [291]\n",
      " [297]\n",
      " [314]\n",
      " [230]\n",
      " [  7]\n",
      " [ 31]\n",
      " [268]\n",
      " [ 26]\n",
      " [267]\n",
      " [153]\n",
      " [289]\n",
      " [292]\n",
      " [288]\n",
      " [285]\n",
      " [280]\n",
      " [274]\n",
      " [262]\n",
      " [248]\n",
      " [233]\n",
      " [226]\n",
      " [221]\n",
      " [220]\n",
      " [202]\n",
      " [185]\n",
      " [166]\n",
      " [162]\n",
      " [157]\n",
      " [156]\n",
      " [145]\n",
      " [142]\n",
      " [140]\n",
      " [132]\n",
      " [ 91]\n",
      " [ 55]\n",
      " [ 46]\n",
      " [ 18]\n",
      " [ 29]\n",
      " [ 28]\n",
      " [ 14]\n",
      " [ 11]\n",
      " [296]\n",
      " [206]\n",
      " [295]\n",
      " [173]\n",
      " [201]\n",
      " [254]\n",
      " [172]\n",
      " [171]\n",
      " [100]\n",
      " [ 99]\n",
      " [ 97]\n",
      " [ 79]\n",
      " [186]\n",
      " [ 58]\n",
      " [190]\n",
      " [191]\n",
      " [192]\n",
      " [193]\n",
      " [194]\n",
      " [195]\n",
      " [196]\n",
      " [197]\n",
      " [232]\n",
      " [107]\n",
      " [177]\n",
      " [ 81]\n",
      " [298]\n",
      " [246]\n",
      " [178]\n",
      " [137]\n",
      " [ 12]\n",
      " [ 13]\n",
      " [ 16]\n",
      " [ 22]\n",
      " [ 34]\n",
      " [ 47]\n",
      " [ 54]\n",
      " [ 60]\n",
      " [109]\n",
      " [138]\n",
      " [203]\n",
      " [204]\n",
      " [207]\n",
      " [227]\n",
      " [228]\n",
      " [241]\n",
      " [250]\n",
      " [276]\n",
      " [ 25]\n",
      " [208]\n",
      " [ 88]\n",
      " [139]\n",
      " [212]\n",
      " [144]\n",
      " [111]\n",
      " [308]\n",
      " [256]\n",
      " [ 39]\n",
      " [ 41]\n",
      " [ 42]\n",
      " [  2]\n",
      " [237]\n",
      " [238]\n",
      " [239]\n",
      " [ 15]\n",
      " [ 66]\n",
      " [ 67]\n",
      " [ 71]\n",
      " [ 72]\n",
      " [242]\n",
      " [243]\n",
      " [ 73]\n",
      " [ 74]\n",
      " [ 76]\n",
      " [ 77]\n",
      " [101]\n",
      " [102]\n",
      " [108]\n",
      " [146]\n",
      " [ 89]\n",
      " [ 86]\n",
      " [257]\n",
      " [ 33]\n",
      " [170]\n",
      " [214]\n",
      " [ 56]\n",
      " [ 57]\n",
      " [ 65]\n",
      " [184]\n",
      " [ 69]\n",
      " [147]\n",
      " [198]\n",
      " [199]\n",
      " [210]\n",
      " [213]\n",
      " [219]\n",
      " [249]\n",
      " [275]\n",
      " [299]\n",
      " [300]\n",
      " [301]\n",
      " [304]\n",
      " [305]\n",
      " [ 85]\n",
      " [218]\n",
      " [279]\n",
      " [306]\n",
      " [174]\n",
      " [175]\n",
      " [179]\n",
      " [287]\n",
      " [ 92]\n",
      " [205]\n",
      " [112]\n",
      " [310]\n",
      " [263]\n",
      " [ 82]\n",
      " [114]\n",
      " [115]\n",
      " [294]\n",
      " [ 48]\n",
      " [160]\n",
      " [163]\n",
      " [269]\n",
      " [270]\n",
      " [271]\n",
      " [164]\n",
      " [312]\n",
      " [251]\n",
      " [282]\n",
      " [265]\n",
      " [293]\n",
      " [ 49]\n",
      " [277]\n",
      " [283]\n",
      " [ 27]\n",
      " [168]\n",
      " [245]\n",
      " [134]\n",
      " [225]\n",
      " [224]\n",
      " [234]\n",
      " [235]\n",
      " [236]\n",
      " [253]\n",
      " [284]\n",
      " [309]\n",
      " [136]\n",
      " [ 45]\n",
      " [ 44]\n",
      " [ 44]\n",
      " [ 43]\n",
      " [159]\n",
      " [110]\n",
      " [216]\n",
      " [307]\n",
      " [183]\n",
      " [152]\n",
      " [  4]\n",
      " [255]\n",
      " [ 59]\n",
      " [ 35]\n",
      " [247]\n",
      " [  5]\n",
      " [ 90]\n",
      " [209]\n",
      " [ 10]\n",
      " [141]\n",
      " [104]\n",
      " [ 40]\n",
      " [150]\n",
      " [148]\n",
      " [259]\n",
      " [266]\n",
      " [ 78]\n",
      " [  3]\n",
      " [105]\n",
      " [109]\n",
      " [ 37]\n",
      " [ 94]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.reshape(-1,1)\n",
    "y = df['Alert Type(ignorable)']\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "\n",
      "***** Logistic Regression classification report:*****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.43      0.35      0.39        34\n",
      "         Yes       0.58      0.66      0.62        47\n",
      "\n",
      "    accuracy                           0.53        81\n",
      "   macro avg       0.51      0.51      0.50        81\n",
      "weighted avg       0.52      0.53      0.52        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "glmMod = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=1.0, fit_intercept=True,\n",
    "                            intercept_scaling=1, class_weight=None, \n",
    "                            random_state=None, solver='liblinear', max_iter=100,\n",
    "                            multi_class='ovr', verbose=2)\n",
    "glmMod.fit(X_train, y_train)\n",
    "y_pred=glmMod.predict(X_test)\n",
    "print(\"\\n\\n***** Logistic Regression classification report:*****\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'logisticMod.pkl'\n",
    "pickle.dump(glmMod, open('logisticMod.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***** RandomForestClassifier report:*****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.56      0.69      0.62        32\n",
      "         Yes       0.76      0.65      0.70        49\n",
      "\n",
      "    accuracy                           0.67        81\n",
      "   macro avg       0.66      0.67      0.66        81\n",
      "weighted avg       0.68      0.67      0.67        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfMod = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2,\n",
    "                               min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto',\n",
    "                               max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=1, \n",
    "                               random_state=None, verbose=0)\n",
    "rfMod.fit(X_train, y_train)\n",
    "y_pred=rfMod.predict(X_test)\n",
    "print(\"\\n\\n***** RandomForestClassifier report:*****\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'randomforestMod.pkl'\n",
    "pickle.dump(rfMod, open('randomforestMod.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***** GradientBoosting report:*****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.59      0.59      0.59        32\n",
      "         Yes       0.73      0.73      0.73        49\n",
      "\n",
      "    accuracy                           0.68        81\n",
      "   macro avg       0.66      0.66      0.66        81\n",
      "weighted avg       0.68      0.68      0.68        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbMod = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200, subsample=1.0,\n",
    "                                   min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                   max_depth=3,\n",
    "                                   init=None, random_state=None, max_features=None, verbose=0)\n",
    "gbMod.fit(X_train, y_train)\n",
    "y_pred=gbMod.predict(X_test)\n",
    "print(\"\\n\\n***** GradientBoosting report:*****\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'gradientboostMod1.pkl'\n",
    "pickle.dump(gbMod, open('gradientboostMod.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***** Adaboost report:*****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.58      0.47      0.52        32\n",
      "         Yes       0.69      0.78      0.73        49\n",
      "\n",
      "    accuracy                           0.65        81\n",
      "   macro avg       0.63      0.62      0.62        81\n",
      "weighted avg       0.65      0.65      0.65        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaMod = AdaBoostClassifier(base_estimator=None, n_estimators=200, learning_rate=1.0)\n",
    "adaMod.fit(X_train, y_train)\n",
    "y_pred = adaMod.predict(X_test)\n",
    "print(\"\\n\\n***** Adaboost report:*****\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'adaboostMod1.pkl'\n",
    "pickle.dump(adaMod, open('adaboostMod1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "\n",
      "***** Model Ensemble score report:*****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.59      0.62      0.61        32\n",
      "         Yes       0.74      0.71      0.73        49\n",
      "\n",
      "    accuracy                           0.68        81\n",
      "   macro avg       0.67      0.67      0.67        81\n",
      "weighted avg       0.68      0.68      0.68        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "votingMod = VotingClassifier(estimators=[('RandomForrest', rfMod),('LogisticRegression', glmMod),(\"GradientBoosting\",gbMod),(\"AdaBoost\",adaMod)], voting='soft')\n",
    "votingMod = votingMod.fit(X_train, y_train)\n",
    "test_labels=votingMod.predict((X_test))\n",
    "#votingMod.score(X_test_transform, y_test)\n",
    "\n",
    "print(\"\\n\\n***** Model Ensemble score report:*****\\n\")\n",
    "print(classification_report(y_test, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'votingclassifierMod1.pkl'\n",
    "pickle.dump(votingMod, open('votingclassifierMod1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\SRAVANTHI SHOROFF\\\\Desktop\\\\sravanthi\\\\SCOM_dump_ML'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
